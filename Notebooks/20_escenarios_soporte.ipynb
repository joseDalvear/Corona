{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24ccc84b-5a7b-48fd-b264-99a60026ba6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Escenario 3.1 – Schema drift en datos de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43236bb9-1f52-4804-a0ad-d0147b5c28c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Es necesario definir las features basado en el esquema inicial estableciendo el conjunto y el orden esperado.\n",
    "\n",
    "Se implementa una rutina de validación y transformacion de esquema, primero se resolvio el problema de nombre inconsistente mediante un bucle de renombrado basado en el mapeo de columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f50f6ed-2c13-41db-92db-f5e60f88af54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "#definicion de las caracteristicas y mapeo de nombres\n",
    "FEATURE_CONTRACT = ['customer_id', 'total_usage', 'avg_calls', 'region_id'] \n",
    "\n",
    "#atributos\n",
    "COLUMN_MAP = {\n",
    "    'cliente_id': 'customer_id',\n",
    "    'uso_total': 'total_usage'\n",
    "}\n",
    "\n",
    "#carga de datos de scoring\n",
    "df_scoring = spark.read.table(\"xxxx\")\n",
    "\n",
    "\n",
    "#aplicar el mapeo de atributos para estandarizar nombres\n",
    "for old_name, new_name in COLUMN_MAP.items():\n",
    "    if old_name in df_scoring.columns:\n",
    "        df_scoring = df_scoring.withColumnRenamed(old_name, new_name)\n",
    "\n",
    "#seleccionar y reordenar el conjunto de atributos\n",
    "select_expr = [col(c) for c in FEATURE_CONTRACT]\n",
    "\n",
    "df_scoring_aligned = df_scoring.select(*select_expr)\n",
    "\n",
    "#verificación del esquema alineado\n",
    "df_scoring_aligned.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "350cc52c-080b-42cc-8c03-42e2d802c068",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Escenario 3.2 – Carga incorrecta de modelo en MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd3aa0b0-ba8d-4bdc-a919-5de4e3fe18a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Error Inicial** La falla fue usar un nombre de modelo incorrecto (churn_model_prod en lugar de churn_model) o especificar un stage (/Production) que no estaba asignado a ninguna versión.\n",
    "\n",
    "**Correccion¨** Se utiliza el MlflowClient para obtener y cargar la última versión numérica disponible (models:/nombre/versión). Esto es mas robusto que depender de un nombre (\"Production\", \"Staging\") e incierto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5dee85f-e4f0-4c77-a1ad-e8c0e1bbfc63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "model_name = \"churn_model\" \n",
    "new_tags = {\n",
    "    \"model_framework\": \"sklearn\",\n",
    "    \"project_id\": \"123456\",\n",
    "    \"model_type\": \"regression\"\n",
    "}\n",
    "\n",
    "#Listar para obtener ultima version\n",
    "#Se obtiene la última version registrada (la de mayor numero)\n",
    "latest_version = client.get_latest_versions(model_name)[0]\n",
    "version_number = latest_version.version\n",
    "model_uri = f\"models:/{model_name}/{version_number}\"\n",
    "\n",
    "#Carga correcta y predecir\n",
    "model = mlflow.pyfunc.load_model(model_uri)\n",
    "df = spark.read.table(\"churn.scoring_features\").toPandas()\n",
    "preds = model.predict(df)\n",
    "\n",
    "#etiqueta\n",
    "for key, value in new_tags.items():\n",
    "    client.set_model_version_tag(\n",
    "        name=model_name, \n",
    "        version=version_number, \n",
    "        key=key, \n",
    "        value=value\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ce4c840-c2fb-4be7-8bec-8ba9d1173480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Escenario 3.3 – Sistema RAG que siempre devuelve contexto vacío"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1255e5ab-6466-4b5b-a898-f7f4b430495e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Problema:** Suponga que por un error en “retrieve_relevant_chunks” siempre se devuelve un DataFrame vacío, por\n",
    "ejemplo, por un ordenamiento/umbral mal aplicado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cefaa93-f5a6-42b5-9911-44d84f652a47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Se podría estar generando el error en este punto, ya que esto seleccionaria los chunks menos parecidos (los de similitud baja), para este caso estaba seleccionando lo mas seguro todo lo negativo, contenido irrelevante y vacio.\n",
    "\n",
    "orderBy(col(\"similarity\").asc())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eda51c57-327b-462c-8ca0-1af79b185676",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Esta versión siempre devuelve k resultados (si el DataFrame tiene datos)\n",
    "Evita el error clásico de ordenar ascendente sin querer\n",
    "Confirma que la columna \"embedding\" existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "968301d5-3f88-47a0-a14a-7accf3d806d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Tambien se podría ralizar a traves de manejo de excepciones pero quiero dejar algo sencillo y rapido para el ejercicio\n",
    "def retrieve_chunks(query_embedding, df_embeddings, k=3):\n",
    "\n",
    "    #Validacion basica (evita DataFrame vacío)\n",
    "    if df_embeddings.count() == 0:\n",
    "        print(\"df_embeddings está vacío.\")\n",
    "        return df_embeddings\n",
    "    \n",
    "    if \"embedding\" not in df_embeddings.columns:\n",
    "        raise Exception(\"La columna 'embedding' no existe en df_embeddings.\")\n",
    "\n",
    "    #calculo de similitud usando tu UDF\n",
    "    df_scored = df_embeddings.withColumn(\n",
    "        \"similarity\",\n",
    "        cos_sim_udf(col(\"embedding\"), lit(query_embedding))\n",
    "    )\n",
    "\n",
    "    #manejo por si la similitud queda como NULL o vectores mal formados\n",
    "    df_scored = df_scored.na.fill({\"similarity\": -1.0})\n",
    "\n",
    "    #orden descendente (nota: siempre las similitudes altas primero)\n",
    "    df_top = df_scored.orderBy(col(\"similarity\").desc()).limit(k)\n",
    "\n",
    "    #log para que siempre veas qué está retornando\n",
    "    print(\"Chunks recuperados (top k):\")\n",
    "    df_top.select(\"chunk_id\", \"similarity\").show()\n",
    "\n",
    "    return df_top"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "20_escenarios_soporte",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}